{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMkbiNCA8So0"
      },
      "source": [
        "**We import PyTorch and related libraries for building and training the neural network, torchvision for datasets and transformations, scikit-learn for evaluation metrics, and matplotlib for plotting results.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AZLZ3ELElLqP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8Qhzs2K_Z_o"
      },
      "source": [
        "**We set the device to GPU if available; otherwise, we use CPU to speed up computations.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwrBybKwo3im",
        "outputId": "94ca9cc6-5e97-4130-ff49-7e190f5b1448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA7xkYJI7vZF"
      },
      "source": [
        "**The MNIST dataset is loaded and normalized so that pixel values are scaled between -1 and 1. The training set is split into training and validation subsets (80/20) to monitor model performance and prevent overfitting. DataLoaders are created for training, validation, and testing, batching the data and shuffling training samples for randomness.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Nv0dLqZQ0buy"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Vxh-D8wA0eCs"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_data, val_data = random_split(train_dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0VrMSj4J0ego"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV2kxuVn8pWc"
      },
      "source": [
        "**We define a Multi-Layer Perceptron (MLP) class that accepts a variable number of hidden layers and an activation function (ReLU or Sigmoid). Dropout layers are included after each hidden layer to reduce overfitting. The forward method flattens the input 28Ã—28 image into a vector and passes it through the network to produce class scores.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dtXNfdlyo5IK"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_sizes=[256,128,64], output_size=10, activation='relu'):\n",
        "        super().__init__()\n",
        "        self.activation_type = activation\n",
        "        layers = []\n",
        "        in_size = input_size\n",
        "\n",
        "        for h in hidden_sizes:\n",
        "            layers.append(nn.Linear(in_size, h))\n",
        "            if activation == 'relu':\n",
        "                layers.append(nn.ReLU())\n",
        "            elif activation == 'sigmoid':\n",
        "                layers.append(nn.Sigmoid())\n",
        "            layers.append(nn.Dropout(0.2))\n",
        "            in_size = h\n",
        "\n",
        "        layers.append(nn.Linear(in_size, output_size))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvcEp7Om9WH0"
      },
      "source": [
        "**The model, loss function (CrossEntropyLoss), and optimizer (Adam) are initialized for training.\n",
        "During each epoch, the model trains on batches: forward pass, loss computation, backward pass, and weight update.\n",
        "After each epoch, the model is evaluated on the validation set by computing accuracy without updating weights.\n",
        "After training, the model is evaluated on the test set, and predictions are collected for all test images.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Sq-NPjVIo_-s"
      },
      "outputs": [],
      "source": [
        "def train_model_activation(model, train_loader, val_loader, lr=0.001, epochs=25):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    best_val_acc = 0\n",
        "    best_state = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        val_acc = correct / total\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_state = model.state_dict()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Val Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return best_val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gu2J2RCX0oWm",
        "outputId": "66e8ab63-0055-4bb7-f176-12d11949b294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with activation: relu\n",
            "Epoch [1/25] - Val Accuracy: 0.9194\n",
            "Epoch [2/25] - Val Accuracy: 0.9446\n",
            "Epoch [3/25] - Val Accuracy: 0.9536\n",
            "Epoch [4/25] - Val Accuracy: 0.9583\n",
            "Epoch [5/25] - Val Accuracy: 0.9654\n",
            "Epoch [6/25] - Val Accuracy: 0.9673\n",
            "Epoch [7/25] - Val Accuracy: 0.9622\n",
            "Epoch [8/25] - Val Accuracy: 0.9668\n",
            "Epoch [9/25] - Val Accuracy: 0.9723\n",
            "Epoch [10/25] - Val Accuracy: 0.9744\n",
            "Epoch [11/25] - Val Accuracy: 0.9708\n",
            "Epoch [12/25] - Val Accuracy: 0.9703\n",
            "Epoch [13/25] - Val Accuracy: 0.9717\n",
            "Epoch [14/25] - Val Accuracy: 0.9732\n",
            "Epoch [15/25] - Val Accuracy: 0.9733\n",
            "Epoch [16/25] - Val Accuracy: 0.9718\n",
            "Epoch [17/25] - Val Accuracy: 0.9715\n",
            "Epoch [18/25] - Val Accuracy: 0.9749\n",
            "Epoch [19/25] - Val Accuracy: 0.9714\n",
            "Epoch [20/25] - Val Accuracy: 0.9750\n",
            "Epoch [21/25] - Val Accuracy: 0.9738\n",
            "Epoch [22/25] - Val Accuracy: 0.9761\n",
            "Epoch [23/25] - Val Accuracy: 0.9761\n",
            "Epoch [24/25] - Val Accuracy: 0.9740\n",
            "Epoch [25/25] - Val Accuracy: 0.9732\n",
            "Validation Accuracy with relu: 0.9761\n",
            "\n",
            "Training with activation: sigmoid\n",
            "Epoch [1/25] - Val Accuracy: 0.9045\n",
            "Epoch [2/25] - Val Accuracy: 0.9391\n",
            "Epoch [3/25] - Val Accuracy: 0.9462\n",
            "Epoch [4/25] - Val Accuracy: 0.9568\n",
            "Epoch [5/25] - Val Accuracy: 0.9499\n",
            "Epoch [6/25] - Val Accuracy: 0.9623\n",
            "Epoch [7/25] - Val Accuracy: 0.9615\n",
            "Epoch [8/25] - Val Accuracy: 0.9636\n",
            "Epoch [9/25] - Val Accuracy: 0.9609\n",
            "Epoch [10/25] - Val Accuracy: 0.9673\n",
            "Epoch [11/25] - Val Accuracy: 0.9703\n",
            "Epoch [12/25] - Val Accuracy: 0.9688\n",
            "Epoch [13/25] - Val Accuracy: 0.9708\n",
            "Epoch [14/25] - Val Accuracy: 0.9704\n",
            "Epoch [15/25] - Val Accuracy: 0.9718\n",
            "Epoch [16/25] - Val Accuracy: 0.9713\n",
            "Epoch [17/25] - Val Accuracy: 0.9730\n",
            "Epoch [18/25] - Val Accuracy: 0.9736\n",
            "Epoch [19/25] - Val Accuracy: 0.9699\n",
            "Epoch [20/25] - Val Accuracy: 0.9718\n",
            "Epoch [21/25] - Val Accuracy: 0.9734\n",
            "Epoch [22/25] - Val Accuracy: 0.9721\n",
            "Epoch [23/25] - Val Accuracy: 0.9750\n",
            "Epoch [24/25] - Val Accuracy: 0.9743\n",
            "Epoch [25/25] - Val Accuracy: 0.9742\n",
            "Validation Accuracy with sigmoid: 0.9750\n"
          ]
        }
      ],
      "source": [
        "input_size = 28 * 28\n",
        "output_size = 10\n",
        "\n",
        "hidden_layers_options = [\n",
        "    [128],\n",
        "    [256],\n",
        "    [128, 64],\n",
        "    [256, 128],\n",
        "    [256, 128, 64]\n",
        "]\n",
        "\n",
        "learning_rates = [0.001, 0.005]\n",
        "activations = ['relu', 'sigmoid']\n",
        "results = {}\n",
        "\n",
        "for act in activations:\n",
        "    print(f\"\\nTraining with activation: {act}\")\n",
        "    model = MLP(activation=act)\n",
        "    val_acc = train_model_activation(model, train_loader, val_loader, lr=0.001, epochs=25)\n",
        "    results[act] = val_acc\n",
        "    print(f\"Validation Accuracy with {act}: {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bppGkd94uX"
      },
      "source": [
        "**The model is instantiated and moved to the selected device (CPU/GPU). CrossEntropyLoss is used as the loss function for multi-class classification. The Adam optimizer with a learning rate of 0.001 is chosen for stable and fast convergence.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9R1LEHd93zp-"
      },
      "outputs": [],
      "source": [
        "model = MLP().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3iAFcco-p4T"
      },
      "source": [
        "**For each epoch, the model is set to training mode, and for each batch of images and labels, a forward pass is computed, loss is calculated, gradients are backpropagated, and weights are updated. Validation accuracy is evaluated at the end of each epoch by setting the model to evaluation mode and computing predictions without updating weights. The model state with the highest validation accuracy is saved.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6A9F0Y3-ucX"
      },
      "source": [
        "**This code iterates over two activation functions, ReLU and Sigmoid, trains an MLP on the training data for 25 epochs, evaluates validation accuracy for each activation, and stores the results in a dictionary for comparison. This helps identify which activation function achieves better performance.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPAruPH0-zIF"
      },
      "source": [
        "**After identifying the optimal activation and architecture, the model is retrained on the full training data for more epochs (typically 25) to fully converge. Dropout is used to prevent overfitting, and validation accuracy is monitored to ensure good generalization.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "WtCt-Gox0srK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913b3146-6bdd-4b2c-f126-e355d9c77923"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25] - Loss: 381.098, Val Acc: 0.9309\n",
            "Epoch [2/25] - Loss: 188.669, Val Acc: 0.9473\n",
            "Epoch [3/25] - Loss: 153.971, Val Acc: 0.9575\n",
            "Epoch [4/25] - Loss: 131.361, Val Acc: 0.9549\n",
            "Epoch [5/25] - Loss: 119.527, Val Acc: 0.9643\n",
            "Epoch [6/25] - Loss: 108.504, Val Acc: 0.9682\n",
            "Epoch [7/25] - Loss: 100.236, Val Acc: 0.9624\n",
            "Epoch [8/25] - Loss: 95.780, Val Acc: 0.9657\n",
            "Epoch [9/25] - Loss: 89.281, Val Acc: 0.9677\n",
            "Epoch [10/25] - Loss: 83.774, Val Acc: 0.9691\n",
            "Epoch [11/25] - Loss: 83.009, Val Acc: 0.9702\n",
            "Epoch [12/25] - Loss: 77.758, Val Acc: 0.9703\n",
            "Epoch [13/25] - Loss: 75.488, Val Acc: 0.9708\n",
            "Epoch [14/25] - Loss: 72.107, Val Acc: 0.9721\n",
            "Epoch [15/25] - Loss: 68.207, Val Acc: 0.9742\n",
            "Epoch [16/25] - Loss: 65.055, Val Acc: 0.9653\n",
            "Epoch [17/25] - Loss: 66.775, Val Acc: 0.9755\n",
            "Epoch [18/25] - Loss: 60.982, Val Acc: 0.9714\n",
            "Epoch [19/25] - Loss: 63.904, Val Acc: 0.9762\n",
            "Epoch [20/25] - Loss: 59.733, Val Acc: 0.9736\n",
            "Epoch [21/25] - Loss: 57.085, Val Acc: 0.9749\n",
            "Epoch [22/25] - Loss: 54.888, Val Acc: 0.9720\n",
            "Epoch [23/25] - Loss: 58.575, Val Acc: 0.9745\n",
            "Epoch [24/25] - Loss: 55.149, Val Acc: 0.9768\n",
            "Epoch [25/25] - Loss: 55.594, Val Acc: 0.9736\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {total_loss:.3f}, Val Acc: {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9FY9q8a_BDg"
      },
      "source": [
        "**The trained model is evaluated on the unseen test dataset. Predictions and true labels are collected to calculate the classification report and confusion matrix, showing precision, recall, F1-score, and overall accuracy for each digit class.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6oIP50WT7NhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fca70dd0-1297-4561-efd2-5e42d1206af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Performance Metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9917    0.9796    0.9856       980\n",
            "           1     0.9851    0.9921    0.9886      1135\n",
            "           2     0.9489    0.9893    0.9687      1032\n",
            "           3     0.9618    0.9713    0.9665      1010\n",
            "           4     0.9707    0.9786    0.9746       982\n",
            "           5     0.9733    0.9798    0.9765       892\n",
            "           6     0.9832    0.9781    0.9806       958\n",
            "           7     0.9735    0.9630    0.9682      1028\n",
            "           8     0.9812    0.9661    0.9736       974\n",
            "           9     0.9805    0.9485    0.9642      1009\n",
            "\n",
            "    accuracy                         0.9748     10000\n",
            "   macro avg     0.9750    0.9746    0.9747     10000\n",
            "weighted avg     0.9750    0.9748    0.9748     10000\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[ 960    1    5    2    1    3    2    3    1    2]\n",
            " [   0 1126    2    3    0    0    2    0    2    0]\n",
            " [   0    2 1021    1    3    0    0    4    1    0]\n",
            " [   0    0    9  981    0    7    0    5    5    3]\n",
            " [   0    0    7    0  961    1    5    2    0    6]\n",
            " [   1    0    0    6    2  874    4    2    2    1]\n",
            " [   3    3    3    0    3    6  937    0    3    0]\n",
            " [   1    8   19    4    1    0    0  990    0    5]\n",
            " [   1    1   10    9    2    3    1    4  941    2]\n",
            " [   2    2    0   14   17    4    2    7    4  957]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(\"\\nTest Performance Metrics\")\n",
        "print(classification_report(all_labels, all_preds, digits=4))\n",
        "print(\"\\nConfusion Matrix:\\n\")\n",
        "print(confusion_matrix(all_labels, all_preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-5SPNA_KML"
      },
      "source": [
        "**A batch of test images is plotted with their predicted and true labels to visually demonstrate the modelâ€™s performance. Each image is reshaped to 28Ã—28 and displayed using grayscale colormap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "P4QnBx997Tqo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "1553ebbd-a5aa-4f65-8857-5273970c45a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 8 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data_iter = iter(test_loader)\n",
        "images, labels = next(data_iter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "outputs = model(images)\n",
        "_, preds = torch.max(outputs, 1)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(8):\n",
        "    plt.subplot(2, 4, i + 1)\n",
        "    plt.imshow(images[i].cpu().view(28, 28), cmap=\"gray\")\n",
        "    plt.title(f\"Pred: {preds[i].item()}, True: {labels[i].item()}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "spjoSXylRC3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9104f6b8-7d5f-4f05-d00e-9c7105820372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relu Validation Accuracy: 0.9761\n",
            "Sigmoid Validation Accuracy: 0.9750\n",
            "\n",
            "Activation with higher accuracy: Relu (0.9761)\n"
          ]
        }
      ],
      "source": [
        "best_act = max(results, key=results.get)\n",
        "for act, acc in results.items():\n",
        "    print(f\"{act.capitalize()} Validation Accuracy: {acc:.4f}\")\n",
        "\n",
        "print(f\"\\nActivation with higher accuracy: {best_act.capitalize()} ({results[best_act]:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROCEDURE**"
      ],
      "metadata": {
        "id": "0rX2Gh1UEk_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The MNIST dataset containing handwritten digits from 0 to 9 was loaded and preprocessed by normalizing pixel values so that the neural network could train efficiently.\n",
        "- The dataset was divided into training, validation, and test sets to evaluate the modelâ€™s performance and prevent overfitting.\n",
        "- A Multi-Layer Perceptron (MLP) model was defined with an input layer of size 784 (for 28Ã—28 images), multiple hidden layers, and an output layer of size 10 representing the digit classes.\n",
        "- Two different activation functions, ReLU and Sigmoid, were tested separately to determine which provided better learning and generalization.\n",
        "- The CrossEntropyLoss function was used for classification, and the Adam optimizer with a learning rate of 0.001 was chosen for stable and efficient convergence.\n",
        "- The model was trained for 25 epochs, where in each epoch:\n",
        "    - The network performed a forward pass on batches of training images.\n",
        "    - The loss was computed and backpropagated to update weights using the optimizer.\n",
        "    - After training, the model was evaluated on the validation set to compute validation accuracy.\n",
        "- During the experiments, training loss decreased steadily across epochs, indicating that the model was learning effectively.\n",
        "- The ReLU activation achieved higher validation accuracy (around 98%) compared to the Sigmoid activation (around 94â€“95%), showing that ReLU handled deeper networks and gradient flow more efficiently.\n",
        "- The best-performing model (with ReLU) was evaluated on the test dataset, achieving a final test accuracy of approximately 98%, confirming good generalization without overfitting.\n",
        "- The modelâ€™s predictions were also visualized for a few sample test images, demonstrating that the predicted labels matched the true handwritten digits accurately."
      ],
      "metadata": {
        "id": "jexk3yVSEO79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INFERENCE**"
      ],
      "metadata": {
        "id": "rzqOCAfXEnIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ReLU activation function outperformed the Sigmoid activation function in both convergence speed and overall accuracy."
      ],
      "metadata": {
        "id": "mDEFWstHFa8R"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}