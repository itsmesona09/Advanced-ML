{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Notebook for External Learning\n",
        "---\n",
        "## Section 1: PyTorch Basics – Tensors"
      ],
      "metadata": {
        "id": "a594940e-cd6b-4e8f-9b40-75a15d67ad32"
      },
      "id": "a594940e-cd6b-4e8f-9b40-75a15d67ad32"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.** What is a `torch.Tensor`? How is it different from a NumPy array?"
      ],
      "metadata": {
        "id": "8bff5440-ab7b-4d01-bed8-36a86de47ba2"
      },
      "id": "8bff5440-ab7b-4d01-bed8-36a86de47ba2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A torch.Tensor is a multi-dimensional array used in PyTorch\n",
        "- It can store and manipulate numerical data\n",
        "- Tensors are similar to NumPy arrays but are optimized for deep learning tasks\n",
        "\n",
        "**Difference**\n",
        "- NumPy arrays are only supported on CPU, while PyTorch tensors can run on CPU and GPU\n",
        "- NumPy does not support automatic differentiation, whereas PyTorch tensors support autograd with requires_grad=True\n",
        "- PyTorch is optimized for deep learning computations, while NumPy is for general scientific computing\n",
        "- Tensors can be easily converted to and from NumPy arrays, making them interoperable"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "08319f6d-2943-406d-b281-49418cc8e006"
      },
      "id": "08319f6d-2943-406d-b281-49418cc8e006"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1 Code Task: Create a 1D tensor with values [1, 2, 3, 4, 5]\n",
        "import torch\n",
        "tensor = torch.Tensor([1, 2, 3, 4, 5])\n",
        "print(\"1D Tensor: \", tensor)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1D Tensor:  tensor([1., 2., 3., 4., 5.])\n"
          ]
        }
      ],
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a87e7c5-7c2e-4cda-9806-0d3f1b637124",
        "outputId": "7089c75e-c446-4930-cf55-02f5fe1a7a7c"
      },
      "id": "9a87e7c5-7c2e-4cda-9806-0d3f1b637124"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** How can you convert a PyTorch tensor to a NumPy array and vice versa?"
      ],
      "metadata": {
        "id": "39cc4851-8152-4d0e-9e32-6390504c8a8d"
      },
      "id": "39cc4851-8152-4d0e-9e32-6390504c8a8d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can convert a NumPy array to PyTorch tensor torch.tensor() or torch.from_numpy().\n",
        "- We can convert a PyTorch Tensor to a NumPy Array using .numpy()"
      ],
      "metadata": {
        "id": "0LOtCZF8jYtR"
      },
      "id": "0LOtCZF8jYtR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2 Code Task: Convert the tensor [10, 20, 30] into a NumPy array and back to a tensor.\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "tensor = torch.tensor([10, 20, 30])\n",
        "print(\"Original Tensor:\", tensor)\n",
        "\n",
        "numpy_array = tensor.numpy()\n",
        "print(\"\\nPyTorch Tensor to NumPy Array:\", numpy_array)\n",
        "print(\"Type: \", type(numpy_array))\n",
        "\n",
        "tensor_back = torch.tensor(numpy_array)\n",
        "print(\"\\nNumPy Array to Tensor:\", tensor_back)\n",
        "print(\"Type: \", type(tensor_back))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor: tensor([10, 20, 30])\n",
            "\n",
            "PyTorch Tensor to NumPy Array: [10 20 30]\n",
            "Type:  <class 'numpy.ndarray'>\n",
            "\n",
            "NumPy Array to Tensor: tensor([10, 20, 30])\n",
            "Type:  <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "554cc5dc-692c-48bb-8186-5091bf0e2fb3",
        "outputId": "9b05f61e-904a-467f-cb57-7b4cbcb75cad"
      },
      "id": "554cc5dc-692c-48bb-8186-5091bf0e2fb3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** Create a **2x3 tensor** filled with random numbers between 0 and 1. Print its shape and data type."
      ],
      "metadata": {
        "id": "93bf19e5-dc40-489d-98c1-2de72886b60d"
      },
      "id": "93bf19e5-dc40-489d-98c1-2de72886b60d"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3 Code Task\n",
        "random_tensor = torch.rand(2, 3)\n",
        "print(\"Random Tensor: \", random_tensor)\n",
        "print(\"Shape: \", random_tensor.shape)\n",
        "print(\"Data Type: \", random_tensor.dtype)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor:  tensor([[0.2656, 0.9617, 0.6913],\n",
            "        [0.8045, 0.0290, 0.3019]])\n",
            "Shape:  torch.Size([2, 3])\n",
            "Data Type:  torch.float32\n"
          ]
        }
      ],
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82f99a93-0946-40a1-b003-b84bda495140",
        "outputId": "1b1a1f8a-d9a6-474a-d200-60696d0b2981"
      },
      "id": "82f99a93-0946-40a1-b003-b84bda495140"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.** Demonstrate element-wise addition and matrix multiplication with tensors. What is the difference between `*` and `@` operators in PyTorch?"
      ],
      "metadata": {
        "id": "58a715cb-88b0-45eb-9ebc-984b264baf72"
      },
      "id": "58a715cb-88b0-45eb-9ebc-984b264baf72"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4 Code Task: Perform element-wise addition and matrix multiplication on two 2x2 tensors.\n",
        "tensor1 = torch.tensor([[1, 2], [3, 4]])\n",
        "tensor2 = torch.tensor([[5, 6], [7, 8]])\n",
        "\n",
        "print(\"Element wise Matrix Addition: \", tensor1 + tensor2)\n",
        "print(\"Element wise Matrix Multiplication: \", tensor1 * tensor2)\n",
        "print(\"Matrix Multiplication: \", tensor1 @ tensor2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element wise Matrix Addition:  tensor([[ 6,  8],\n",
            "        [10, 12]])\n",
            "Element wise Matrix Multiplication:  tensor([[ 5, 12],\n",
            "        [21, 32]])\n",
            "Matrix Multiplication:  tensor([[19, 22],\n",
            "        [43, 50]])\n"
          ]
        }
      ],
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d181c2ba-82a9-469b-a87f-6daafe9ca340",
        "outputId": "9dbd91d3-d80c-4a72-d608-fa6f826b95c5"
      },
      "id": "d181c2ba-82a9-469b-a87f-6daafe9ca340"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.** Explain broadcasting in PyTorch with an example."
      ],
      "metadata": {
        "id": "7bdb98e1-27e7-4e33-a091-a61594b16aa9"
      },
      "id": "7bdb98e1-27e7-4e33-a091-a61594b16aa9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Broadcasting is a mechanism that allows PyTorch to perform element-wise operations on tensors of different shapes by automatically expanding the smaller tensor to match the larger tensor’s shape.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "a = torch.tensor([[1], [2], [3]])\n",
        "\n",
        "b = torch.tensor([[10, 20, 30, 40]])\n",
        "\n",
        "Broadcasting happens automatically for element-wise addition\n",
        "\n",
        "c = a + b\n",
        "\n",
        "a has shape (3,1) with 3 rows, 1 column\n",
        "\n",
        "b has shape (1,4) with 1 row, 4 columns\n",
        "\n",
        "After broadcasting, a is stretched to (3,4) and b is stretched to (3,4) element wise addition is performed"
      ],
      "metadata": {
        "id": "M-nFfEJioAtR"
      },
      "id": "M-nFfEJioAtR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5 Code Task: Add a tensor of shape (3,1) to a tensor of shape (3,4).\n",
        "# Tensor of shape (3,1)\n",
        "tensor_a = torch.tensor([[1], [2], [3]])\n",
        "# Tensor of shape (3,4)\n",
        "tensor_b = torch.tensor([[10, 20, 30, 40],\n",
        "                         [50, 60, 70, 80],\n",
        "                         [90, 100, 110, 120]])\n",
        "# Broadcasting addition\n",
        "result = tensor_a + tensor_b\n",
        "\n",
        "print(\"\\nTensor a (3,1):\\n\", tensor_a)\n",
        "print(\"\\nTensor b (3,4):\\n\", tensor_b)\n",
        "print(\"\\nAfter broadcasting (a + b):\\n\", result)\n",
        "print(\"\\nShape of result:\", result.shape)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tensor a (3,1):\n",
            " tensor([[1],\n",
            "        [2],\n",
            "        [3]])\n",
            "\n",
            "Tensor b (3,4):\n",
            " tensor([[ 10,  20,  30,  40],\n",
            "        [ 50,  60,  70,  80],\n",
            "        [ 90, 100, 110, 120]])\n",
            "\n",
            "After broadcasting (a + b):\n",
            " tensor([[ 11,  21,  31,  41],\n",
            "        [ 52,  62,  72,  82],\n",
            "        [ 93, 103, 113, 123]])\n",
            "\n",
            "Shape of result: torch.Size([3, 4])\n"
          ]
        }
      ],
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "230444bf-c2a0-428c-a152-9dc2e771091b",
        "outputId": "dcdbba1f-bcbe-4db5-f8c5-f064bcc616ed"
      },
      "id": "230444bf-c2a0-428c-a152-9dc2e771091b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.** What is the difference between `view()` and `reshape()` in PyTorch?"
      ],
      "metadata": {
        "id": "0cda3915-7599-4996-a1b5-b6ed1f296695"
      },
      "id": "0cda3915-7599-4996-a1b5-b6ed1f296695"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- view() and reshape() are used to change the shape of a tensor\n",
        "\n",
        "**view()**\n",
        "- Returns a new tensor with the same data but a different shape\n",
        "- Requires that the tensor be contiguous in memory\n",
        "- If the tensor is not contiguous, you need to call .contiguous() before using view()\n",
        "\n",
        "**reshape()**\n",
        "- Returns a tensor with the desired shape\n",
        "- Automatically handles non-contiguous tensors by returning a copy if needed\n",
        "- More flexible than view()"
      ],
      "metadata": {
        "id": "lUA2bDxCp7G3"
      },
      "id": "lUA2bDxCp7G3"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6 Code Task: Create a tensor of shape (2,3) and reshape it to (3,2).\n",
        "# Create a tensor of shape (2,3)\n",
        "tensor = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6]])\n",
        "print(\"Original Tensor (2x3):\\n\", tensor)\n",
        "print(\"Shape:\", tensor.shape)\n",
        "\n",
        "# Reshape to (3,2) using reshape()\n",
        "reshaped_tensor = tensor.reshape(3, 2)\n",
        "print(\"\\nReshaped Tensor (3x2):\\n\", reshaped_tensor)\n",
        "print(\"Shape:\", reshaped_tensor.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor (2x3):\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Shape: torch.Size([2, 3])\n",
            "\n",
            "Reshaped Tensor (3x2):\n",
            " tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "Shape: torch.Size([3, 2])\n"
          ]
        }
      ],
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c804151-323a-4ce8-bc3d-b299408c2106",
        "outputId": "7a982b0e-6fa2-4775-c113-813d5f633718"
      },
      "id": "0c804151-323a-4ce8-bc3d-b299408c2106"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.** How do you check if a tensor is allocated on **CPU or GPU**?"
      ],
      "metadata": {
        "id": "eefbc3ec-7f9f-461c-b189-ceff82294f65"
      },
      "id": "eefbc3ec-7f9f-461c-b189-ceff82294f65"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In PyTorch, each tensor has a device attribute that tells you where it is stored\n",
        "- tensor.device shows the device where the tensor is stored."
      ],
      "metadata": {
        "id": "pVYrw62Dqaf_"
      },
      "id": "pVYrw62Dqaf_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7 Code Task: Create a tensor and move it to GPU (if available).\n",
        "# Create a tensor on CPU\n",
        "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
        "print(\"Original Tensor:\", tensor)\n",
        "print(\"Device:\", tensor.device)\n",
        "\n",
        "# Move tensor to GPU\n",
        "if torch.cuda.is_available():\n",
        "    tensor_gpu = tensor.to('cuda')\n",
        "    print(\"\\nTensor moved to GPU:\", tensor_gpu)\n",
        "    print(\"Device:\", tensor_gpu.device)\n",
        "else:\n",
        "    print(\"\\nGPU not available. Tensor remains on CPU.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor: tensor([1, 2, 3, 4, 5])\n",
            "Device: cpu\n",
            "\n",
            "GPU not available. Tensor remains on CPU.\n"
          ]
        }
      ],
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e41482b7-5d2f-422e-b2a3-8f865bf32647",
        "outputId": "5dc26481-d27b-48ac-b1e7-bd091b19922a"
      },
      "id": "e41482b7-5d2f-422e-b2a3-8f865bf32647"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.** Create an **identity matrix** of size 4x4 in PyTorch."
      ],
      "metadata": {
        "id": "59c99e8d-9a77-48e5-a692-fa18c55cc70b"
      },
      "id": "59c99e8d-9a77-48e5-a692-fa18c55cc70b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8 Code Task\n",
        "identity_matrix = torch.eye(4)\n",
        "\n",
        "print(\"Identity Matrix (4x4):\\n\", identity_matrix)\n",
        "print(\"Shape:\", identity_matrix.shape)\n",
        "print(\"Data Type:\", identity_matrix.dtype)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Identity Matrix (4x4):\n",
            " tensor([[1., 0., 0., 0.],\n",
            "        [0., 1., 0., 0.],\n",
            "        [0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1.]])\n",
            "Shape: torch.Size([4, 4])\n",
            "Data Type: torch.float32\n"
          ]
        }
      ],
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30be8cd7-47f1-46d0-95ce-75202a81ae0e",
        "outputId": "46e0c385-70ec-4329-fcca-9b49609490ee"
      },
      "id": "30be8cd7-47f1-46d0-95ce-75202a81ae0e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.** How do you find the maximum, minimum, and mean values of a tensor?"
      ],
      "metadata": {
        "id": "55d82487-7162-40db-92dd-f14361ac66a2"
      },
      "id": "55d82487-7162-40db-92dd-f14361ac66a2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tensor.max() returns the largest element in the tensor.\n",
        "- tensor.min() returns the smallest element in the tensor.\n",
        "- tensor.mean() returns the average of all elements."
      ],
      "metadata": {
        "id": "D1OQaprbrEYc"
      },
      "id": "D1OQaprbrEYc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9 Code Task: Compute max, min, mean of tensor [4, 7, 9, 2, 5].\n",
        "tensor = torch.tensor([4, 7, 9, 2, 5], dtype=torch.float32)\n",
        "\n",
        "# Maximum value\n",
        "max_value = tensor.max()\n",
        "print(\"Maximum Value:\", max_value)\n",
        "\n",
        "# Minimum value\n",
        "min_value = tensor.min()\n",
        "print(\"Minimum Value:\", min_value)\n",
        "\n",
        "# Mean value\n",
        "mean_value = tensor.mean()\n",
        "print(\"Mean Value:\", mean_value)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Value: tensor(9.)\n",
            "Minimum Value: tensor(2.)\n",
            "Mean Value: tensor(5.4000)\n"
          ]
        }
      ],
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6e9eb40-1ee4-49dc-8ded-1274624b1e10",
        "outputId": "53808ffb-4d5e-49eb-85ed-e4b3005af0a4"
      },
      "id": "d6e9eb40-1ee4-49dc-8ded-1274624b1e10"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.** Explain slicing and indexing in tensors with an example."
      ],
      "metadata": {
        "id": "02de761c-1dd2-450d-b57e-6b54b8d6e4d6"
      },
      "id": "02de761c-1dd2-450d-b57e-6b54b8d6e4d6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Slicing and indexing in PyTorch tensors allow you to access specific elements, rows, columns, or sub-tensors\n",
        "- Indexing use integer indices to access a specific element\n",
        "- Slicing use to select ranges of rows or columns\n",
        "\n",
        "**Example:**\n",
        "\n",
        "tensor[row, col] → Access a single element\n",
        "\n",
        "tensor[start:end, :] → Slice rows\n",
        "\n",
        "tensor[:, start:end] → Slice columns"
      ],
      "metadata": {
        "id": "0azkv6jKrhsO"
      },
      "id": "0azkv6jKrhsO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q10 Code Task: Create a 3x3 tensor and extract the first row and last column.\n",
        "tensor = torch.tensor([[1, 2, 3],\n",
        "                       [4, 5, 6],\n",
        "                       [7, 8, 9]])\n",
        "print(\"Original Tensor:\\n\", tensor)\n",
        "\n",
        "# Step 2: Extract the first row\n",
        "first_row = tensor[0, :]\n",
        "print(\"\\nFirst Row:\", first_row)\n",
        "\n",
        "# Step 3: Extract the last column\n",
        "last_column = tensor[:, -1]\n",
        "print(\"Last Column:\", last_column)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tensor:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "\n",
            "First Row: tensor([1, 2, 3])\n",
            "Last Column: tensor([3, 6, 9])\n"
          ]
        }
      ],
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57dc5039-a85e-4ec6-b652-d96949070a43",
        "outputId": "8e4ea615-40a0-43ff-8d33-bcdcdfc555d5"
      },
      "id": "57dc5039-a85e-4ec6-b652-d96949070a43"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Section 2: Autograd & Gradients"
      ],
      "metadata": {
        "id": "376ba445-4ef2-433d-b4b1-6f6f99530243"
      },
      "id": "376ba445-4ef2-433d-b4b1-6f6f99530243"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11.** What is autograd in PyTorch? Why is it useful?"
      ],
      "metadata": {
        "id": "41177c15-12e0-439a-b9e1-538a943af839"
      },
      "id": "41177c15-12e0-439a-b9e1-538a943af839"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Autograd is PyTorch’s automatic differentiation engine that powers neural network training\n",
        "- It automatically computes gradients of tensors with respect to some scalar value using the computational graph\n",
        "\n",
        "**Uses:**\n",
        "- Enables automatic computation of derivatives for backpropagation\n",
        "- Simplifies the training of neural networks by removing the need to manually compute gradients\n",
        "- Works seamlessly with CPU and GPU tensors"
      ],
      "metadata": {
        "id": "B7qFnn4Xsg4A"
      },
      "id": "B7qFnn4Xsg4A"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q11 Code Task: Create a tensor `x` with requires_grad=True and compute gradient of y = x**2\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "\n",
        "# Define y = x^2\n",
        "y = x ** 2\n",
        "\n",
        "# Compute gradients\n",
        "y.backward()\n",
        "\n",
        "# Print the gradient\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)\n",
        "print(\"Gradient:\", x.grad)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([3.], requires_grad=True)\n",
            "y: tensor([9.], grad_fn=<PowBackward0>)\n",
            "Gradient: tensor([6.])\n"
          ]
        }
      ],
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8c56068-4cae-4b18-b05f-3d886300f82e",
        "outputId": "60225ddd-06af-4898-81d0-9f585ef3875e"
      },
      "id": "e8c56068-4cae-4b18-b05f-3d886300f82e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12.** Explain the difference between `.backward()` and `.detach()`."
      ],
      "metadata": {
        "id": "287b9396-71d6-496b-a56e-79dd67691803"
      },
      "id": "287b9396-71d6-496b-a56e-79dd67691803"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- .backward() is used to compute gradients for optimization\n",
        "- .detach() is used to stop tracking gradients and treat a tensor as a constant in further computations"
      ],
      "metadata": {
        "id": "HVkrWshatDnI"
      },
      "id": "HVkrWshatDnI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q12 Code Task: Show how to stop gradient tracking for a tensor.\n",
        "# Create a tensor with requires_grad=True\n",
        "x = torch.tensor([3.0], requires_grad=True)\n",
        "print(\"Original tensor:\", x)\n",
        "print(\"Requires grad:\", x.requires_grad)\n",
        "\n",
        "# Perform some operations with gradient tracking\n",
        "y = x ** 2\n",
        "print(\"y = x^2:\", y)\n",
        "print(\"y requires grad:\", y.requires_grad)\n",
        "\n",
        "# Detach the tensor to stop gradient tracking\n",
        "y_detached = y.detach()\n",
        "print(\"\\nDetached tensor:\", y_detached)\n",
        "print(\"Detached tensor requires grad:\", y_detached.requires_grad)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tensor: tensor([3.], requires_grad=True)\n",
            "Requires grad: True\n",
            "y = x^2: tensor([9.], grad_fn=<PowBackward0>)\n",
            "y requires grad: True\n",
            "\n",
            "Detached tensor: tensor([9.])\n",
            "Detached tensor requires grad: False\n"
          ]
        }
      ],
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b438abb4-4fda-4bb9-96d9-e09937542227",
        "outputId": "36a8b1b3-09e9-4ce4-8ad6-6726901eb771"
      },
      "id": "b438abb4-4fda-4bb9-96d9-e09937542227"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13.** Compute gradients for y = 3x^3 + 2x^2 + 5 at x=2 using autograd."
      ],
      "metadata": {
        "id": "84d6b2fa-94b5-4913-8322-8d373678ee4c"
      },
      "id": "84d6b2fa-94b5-4913-8322-8d373678ee4c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q13 Code Task\n",
        "x = torch.tensor([2.0], requires_grad=True)\n",
        "\n",
        "# Define the function y = 3x^3 + 2x^2 + 5\n",
        "y = 3*x**3 + 2*x**2 + 5\n",
        "\n",
        "# Compute gradient\n",
        "y.backward()\n",
        "\n",
        "# Print gradient\n",
        "print(\"x:\", x.item())\n",
        "print(\"y:\", y.item())\n",
        "print(\"Gradient at x=2:\", x.grad.item())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: 2.0\n",
            "y: 37.0\n",
            "Gradient at x=2: 44.0\n"
          ]
        }
      ],
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "299fff30-29a4-4d8a-b223-594c8feea67e",
        "outputId": "6fe3630d-7dfe-4456-82bc-27ac733b9d06"
      },
      "id": "299fff30-29a4-4d8a-b223-594c8feea67e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14.** What happens if you call `.backward()` on a tensor without `requires_grad=True`?"
      ],
      "metadata": {
        "id": "dfb4200b-3d9d-4752-b914-8466b6ff823e"
      },
      "id": "dfb4200b-3d9d-4752-b914-8466b6ff823e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If a tensor does not have requires_grad=True, PyTorch will not track operations on it\n",
        "- Calling .backward() on such a tensor will raise an error because gradients cannot be computed for tensors that are not part of the computation graph"
      ],
      "metadata": {
        "id": "xhpCYxfWt-Cp"
      },
      "id": "xhpCYxfWt-Cp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q14 Code Task: Demonstrate the error with an example.\n",
        "x = torch.tensor([3.0])\n",
        "print(\"Tensor x:\", x)\n",
        "print(\"Requires grad:\", x.requires_grad)\n",
        "\n",
        "# Define a function of x\n",
        "y = x ** 2\n",
        "print(\"y = x^2:\", y)\n",
        "\n",
        "# Attempt to compute gradient\n",
        "try:\n",
        "    y.backward()\n",
        "except RuntimeError as e:\n",
        "    print(\"\\nError when calling backward():\", e)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor x: tensor([3.])\n",
            "Requires grad: False\n",
            "y = x^2: tensor([9.])\n",
            "\n",
            "Error when calling backward(): element 0 of tensors does not require grad and does not have a grad_fn\n"
          ]
        }
      ],
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56178162-edad-4fac-931b-1e10eb1f82e3",
        "outputId": "6b81d50a-4e08-418b-f265-fe1f9ddfd70d"
      },
      "id": "56178162-edad-4fac-931b-1e10eb1f82e3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15.** Perform gradient descent on f(w) = (w-3)^2 for 10 iterations with learning rate 0.1."
      ],
      "metadata": {
        "id": "b0e63ec9-6eb2-4c7a-a7ac-df1bad7b248b"
      },
      "id": "b0e63ec9-6eb2-4c7a-a7ac-df1bad7b248b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q15 Code Task\n",
        "# Initialize w with requires_grad=True\n",
        "w = torch.tensor([0.0], requires_grad=True)\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Gradient descent loop\n",
        "for i in range(10):\n",
        "    f = (w - 3) ** 2\n",
        "    f.backward()\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "    w.grad.zero_()\n",
        "    print(f\"Iteration {i+1}: w = {w.item()}, f(w) = {f.item()}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: w = 0.6000000238418579, f(w) = 9.0\n",
            "Iteration 2: w = 1.0800000429153442, f(w) = 5.760000228881836\n",
            "Iteration 3: w = 1.4639999866485596, f(w) = 3.6863999366760254\n",
            "Iteration 4: w = 1.7711999416351318, f(w) = 2.3592960834503174\n",
            "Iteration 5: w = 2.0169599056243896, f(w) = 1.5099495649337769\n",
            "Iteration 6: w = 2.2135679721832275, f(w) = 0.9663678407669067\n",
            "Iteration 7: w = 2.370854377746582, f(w) = 0.6184753179550171\n",
            "Iteration 8: w = 2.4966835975646973, f(w) = 0.39582422375679016\n",
            "Iteration 9: w = 2.597346782684326, f(w) = 0.2533273994922638\n",
            "Iteration 10: w = 2.677877426147461, f(w) = 0.16212961077690125\n"
          ]
        }
      ],
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36ab3144-c7c9-49c7-b1a1-d7424a206464",
        "outputId": "cdba7377-67ae-40a5-a602-17b70df52b3b"
      },
      "id": "36ab3144-c7c9-49c7-b1a1-d7424a206464"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Section 3: Building Neural Networks"
      ],
      "metadata": {
        "id": "0dc6bf79-c8c3-40d4-91c5-a60a8a9b8f8e"
      },
      "id": "0dc6bf79-c8c3-40d4-91c5-a60a8a9b8f8e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q16.** What is `torch.nn.Module` and why is it useful?"
      ],
      "metadata": {
        "id": "e1c20373-bcd4-497c-bcc5-e8ede078601c"
      },
      "id": "e1c20373-bcd4-497c-bcc5-e8ede078601c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torch.nn.Module is the base class for all neural network models in PyTorch\n",
        "- It provides a convenient way to define, organize, and manage layers and parameters in a model"
      ],
      "metadata": {
        "id": "GQxdO3hGuwnY"
      },
      "id": "GQxdO3hGuwnY"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q16 Code Task: Define a simple linear model y = Wx + b using torch.nn.Linear\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model\n",
        "class LinearModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "model = LinearModel()\n",
        "print(model)\n",
        "\n",
        "x_sample = torch.tensor([[2.0]])\n",
        "y_sample = model(x_sample)\n",
        "print(\"Input:\", x_sample)\n",
        "print(\"Output:\", y_sample)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearModel(\n",
            "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
            ")\n",
            "Input: tensor([[2.]])\n",
            "Output: tensor([[-0.9133]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e375910-58d4-4055-9c52-2b570649a4b1",
        "outputId": "f0c0d8d1-8294-444f-e5a5-dbe15a2e3fa1"
      },
      "id": "6e375910-58d4-4055-9c52-2b570649a4b1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q17.** Create a feedforward neural network with 2 input features, 1 hidden layer (size=4, ReLU), and 1 output."
      ],
      "metadata": {
        "id": "99f26741-bb7b-4287-95dd-d30af155a1d2"
      },
      "id": "99f26741-bb7b-4287-95dd-d30af155a1d2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q17 Code Task\n",
        "# Define the feedforward neural network\n",
        "class FeedforwardNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeedforwardNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 4)\n",
        "        self.fc2 = nn.Linear(4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = FeedforwardNN()\n",
        "print(model)\n",
        "\n",
        "x_sample = torch.tensor([[1.0, 2.0]])\n",
        "y_sample = model(x_sample)\n",
        "print(\"Input:\", x_sample)\n",
        "print(\"Output:\", y_sample)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeedforwardNN(\n",
            "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
            "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n",
            "Input: tensor([[1., 2.]])\n",
            "Output: tensor([[-0.1303]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f73b988-7180-4e6b-ad69-da9ba8c4bbf0",
        "outputId": "fb7d5012-6093-42dd-c250-b637bd214a18"
      },
      "id": "3f73b988-7180-4e6b-ad69-da9ba8c4bbf0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q18.** Explain the role of activation functions. Implement ReLU and Sigmoid manually in PyTorch."
      ],
      "metadata": {
        "id": "1bff69f7-bd76-4b86-843a-044d83916eed"
      },
      "id": "1bff69f7-bd76-4b86-843a-044d83916eed"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Activation functions introduce non-linearity into neural networks, allowing them to learn complex patterns\n",
        "- Without activation functions, a neural network would behave like a linear model, regardless of its depth\n",
        "\n",
        "**Common activation functions**\n",
        "- ReLU (Rectified Linear Unit): f(x) = max(0, x)\n",
        "\n",
        "Pros: Simple, avoids vanishing gradients for positive inputs.\n",
        "\n",
        "- Sigmoid: f(x) = 1 / (1 + exp(-x))\n",
        "\n",
        "Pros: Maps output to range [0,1], useful for probabilities.\n",
        "\n",
        "Cons: Can suffer from vanishing gradients for large positive/negative inputs."
      ],
      "metadata": {
        "id": "pH2FMi-3va9w"
      },
      "id": "pH2FMi-3va9w"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q18 Code Task: Define functions relu(x) and sigmoid(x) using tensors.\n",
        "x = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])\n",
        "\n",
        "# ReLU implementation\n",
        "def relu(x):\n",
        "    return torch.maximum(torch.tensor(0.0), x)\n",
        "\n",
        "# Sigmoid implementation\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + torch.exp(-x))\n",
        "\n",
        "# Test the functions\n",
        "relu_result = relu(x)\n",
        "sigmoid_result = sigmoid(x)\n",
        "\n",
        "print(\"Input:\", x)\n",
        "print(\"ReLU output:\", relu_result)\n",
        "print(\"Sigmoid output:\", sigmoid_result)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([-2., -1.,  0.,  1.,  2.])\n",
            "ReLU output: tensor([0., 0., 0., 1., 2.])\n",
            "Sigmoid output: tensor([0.1192, 0.2689, 0.5000, 0.7311, 0.8808])\n"
          ]
        }
      ],
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45ec55a5-21f4-4665-80f3-0ae58e4e0c8f",
        "outputId": "e3355d8f-9749-4c46-902c-0e77d100366e"
      },
      "id": "45ec55a5-21f4-4665-80f3-0ae58e4e0c8f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q19.** What is the difference between `model.parameters()` and `model.state_dict()`?"
      ],
      "metadata": {
        "id": "67111b22-8bc9-44f2-86db-a3224ed8584c"
      },
      "id": "67111b22-8bc9-44f2-86db-a3224ed8584c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- model.parameters() only the learnable parameters, used by optimizers\n",
        "- model.state_dict() full dictionary of parameters and buffers, used for saving/loading models"
      ],
      "metadata": {
        "id": "1D2Z1o41wuSa"
      },
      "id": "1D2Z1o41wuSa"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q19 Code Task: Print the parameters of a small linear layer.\n",
        "linear_layer = nn.Linear(2, 1)\n",
        "\n",
        "# Print model parameters using model.parameters()\n",
        "print(\"Using model.parameters():\")\n",
        "for param in linear_layer.parameters():\n",
        "    print(param)\n",
        "\n",
        "# Print model parameters using model.state_dict()\n",
        "print(\"\\nUsing model.state_dict():\")\n",
        "for key, value in linear_layer.state_dict().items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using model.parameters():\n",
            "Parameter containing:\n",
            "tensor([[0.4080, 0.6143]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0554], requires_grad=True)\n",
            "\n",
            "Using model.state_dict():\n",
            "weight: tensor([[0.4080, 0.6143]])\n",
            "bias: tensor([-0.0554])\n"
          ]
        }
      ],
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1df72d3-c996-4936-b85f-5262b5c38360",
        "outputId": "1355e328-39c5-4a01-8577-257e936aa873"
      },
      "id": "d1df72d3-c996-4936-b85f-5262b5c38360"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q20.** Implement forward pass of a 2-layer network without using nn.Module."
      ],
      "metadata": {
        "id": "a9644372-c126-4bb5-a0c9-5f5f35d72818"
      },
      "id": "a9644372-c126-4bb5-a0c9-5f5f35d72818"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q20 Code Task\n",
        "x = torch.tensor([[0.5, -1.5]])\n",
        "\n",
        "# Initialize weights and biases\n",
        "# Layer 1: 2 inputs and 3 hidden neurons\n",
        "W1 = torch.randn(2, 3, requires_grad=True)\n",
        "b1 = torch.randn(3, requires_grad=True)\n",
        "\n",
        "# Layer 2: 3 hidden neurons -> 1 output\n",
        "W2 = torch.randn(3, 1, requires_grad=True)\n",
        "b2 = torch.randn(1, requires_grad=True)\n",
        "\n",
        "# Forward pass\n",
        "# Layer 1: Linear + ReLU\n",
        "z1 = x @ W1 + b1\n",
        "a1 = torch.relu(z1)\n",
        "\n",
        "# Layer 2: Linear\n",
        "z2 = a1 @ W2 + b2\n",
        "output = z2\n",
        "\n",
        "print(\"Input:\", x)\n",
        "print(\"Hidden activations (ReLU):\", a1)\n",
        "print(\"Network output:\", output)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([[ 0.5000, -1.5000]])\n",
            "Hidden activations (ReLU): tensor([[0.0000, 1.1677, 0.0000]], grad_fn=<ReluBackward0>)\n",
            "Network output: tensor([[3.1350]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fbf1a6f-c23f-49d7-8488-e9566c779671",
        "outputId": "7215c240-5195-48f0-8597-ceaa7d87f0d7"
      },
      "id": "3fbf1a6f-c23f-49d7-8488-e9566c779671"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Section 4: Training a Simple Model (Logic Gates)"
      ],
      "metadata": {
        "id": "2bb49f63-6f04-438a-a7ee-a8eff3448daf"
      },
      "id": "2bb49f63-6f04-438a-a7ee-a8eff3448daf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q21.** What is the purpose of a loss function? Give two common examples."
      ],
      "metadata": {
        "id": "644bc7d5-86c8-4fd7-9df9-194dbb36cfbf"
      },
      "id": "644bc7d5-86c8-4fd7-9df9-194dbb36cfbf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A loss function (or cost function) measures how well a neural network's predictions match the true target values\n",
        "- It quantifies the error of the model, and training algorithms use it to update the model parameters via gradient descent\n",
        "\n",
        "**Purpose**:\n",
        "- Provides a metric for model performance during training\n",
        "- Guides optimization by computing gradients for backpropagation\n",
        "- Helps in comparing different models or architectures\n",
        "\n",
        "**Example:**\n",
        "1. Mean Squared Error (MSE)\n",
        "- Used for regression tasks\n",
        "\n",
        "2. Binary Cross-Entropy (BCE)\n",
        "- Used for binary classification tasks"
      ],
      "metadata": {
        "id": "_LM61aAzxf9h"
      },
      "id": "_LM61aAzxf9h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q21 Code Task: Use torch.nn.MSELoss to compute loss between y_true=[1.0, 2.0] and y_pred=[1.5, 2.5].\n",
        "y_true = torch.tensor([1.0, 2.0])\n",
        "y_pred = torch.tensor([1.5, 2.5])\n",
        "\n",
        "# Define the MSE loss function\n",
        "mse_loss = nn.MSELoss()\n",
        "\n",
        "# Compute the loss\n",
        "loss = mse_loss(y_pred, y_true)\n",
        "\n",
        "# Print the results\n",
        "print(\"y_true:\", y_true)\n",
        "print(\"y_pred:\", y_pred)\n",
        "print(\"MSE Loss:\", loss.item())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_true: tensor([1., 2.])\n",
            "y_pred: tensor([1.5000, 2.5000])\n",
            "MSE Loss: 0.25\n"
          ]
        }
      ],
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e67f0f0a-7227-424d-8ffd-5ec8f46c34d3",
        "outputId": "69c17ef8-0546-4523-c7dd-5256c7d35488"
      },
      "id": "e67f0f0a-7227-424d-8ffd-5ec8f46c34d3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q22.** What is the role of an optimizer in training neural networks?"
      ],
      "metadata": {
        "id": "27001974-8db9-4665-8ec1-5a59f7c6fe1a"
      },
      "id": "27001974-8db9-4665-8ec1-5a59f7c6fe1a"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- An optimizer in PyTorch is responsible for updating the model's learnable parameters (weights and biases) to minimize the loss function during training"
      ],
      "metadata": {
        "id": "IP1VnjjRybjD"
      },
      "id": "IP1VnjjRybjD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q22 Code Task: Define SGD optimizer for a linear model with learning rate=0.01.\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define a simple linear model\n",
        "model = nn.Linear(1, 1)  # y = Wx + b\n",
        "\n",
        "# Define the SGD optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Print optimizer details\n",
        "print(optimizer)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd0b6550-9430-41c9-881e-bb7af68b118f",
        "outputId": "675cae1a-c48d-4459-d9bb-8b938cf5b2f3"
      },
      "id": "fd0b6550-9430-41c9-881e-bb7af68b118f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q23.** Train a simple linear regression model to fit y = 2x + 1 for x in [1,2,3,4,5]."
      ],
      "metadata": {
        "id": "68469867-936c-4d18-ae03-a5310efa5363"
      },
      "id": "68469867-936c-4d18-ae03-a5310efa5363"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q23 Code Task\n",
        "# Prepare the dataset\n",
        "x_train = torch.tensor([[1.0], [2.0], [3.0], [4.0], [5.0]])\n",
        "y_train = torch.tensor([[3.0], [5.0], [7.0], [9.0], [11.0]])  # y = 2x + 1\n",
        "\n",
        "# Define the model\n",
        "model = nn.Linear(1, 1)\n",
        "\n",
        "# Define loss function (MSE) and optimizer (SGD)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    y_pred = model(x_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"\\nLearned weight:\", model.weight.item())\n",
        "print(\"Learned bias:\", model.bias.item())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/500, Loss: 0.1062\n",
            "Epoch 100/500, Loss: 0.0757\n",
            "Epoch 150/500, Loss: 0.0539\n",
            "Epoch 200/500, Loss: 0.0384\n",
            "Epoch 250/500, Loss: 0.0274\n",
            "Epoch 300/500, Loss: 0.0195\n",
            "Epoch 350/500, Loss: 0.0139\n",
            "Epoch 400/500, Loss: 0.0099\n",
            "Epoch 450/500, Loss: 0.0071\n",
            "Epoch 500/500, Loss: 0.0050\n",
            "\n",
            "Learned weight: 2.045926332473755\n",
            "Learned bias: 0.8341917395591736\n"
          ]
        }
      ],
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66c7d8b9-1de8-4b24-982a-87fdb6ba1318",
        "outputId": "b936debf-59a0-4de0-d443-e3a41f5d0099"
      },
      "id": "66c7d8b9-1de8-4b24-982a-87fdb6ba1318"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q24.** Implement and train a neural network for the AND gate."
      ],
      "metadata": {
        "id": "0a6c0bc7-2fe0-496c-ab4c-2a234d0fd20e"
      },
      "id": "0a6c0bc7-2fe0-496c-ab4c-2a234d0fd20e"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q24 Code Task\n",
        "# Prepare the AND gate dataset\n",
        "x_train = torch.tensor([[0,0], [0,1], [1,0], [1,1]], dtype=torch.float32)\n",
        "y_train = torch.tensor([[0], [0], [0], [1]], dtype=torch.float32)\n",
        "\n",
        "# Define a simple feedforward neural network\n",
        "class ANDNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANDNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 2)\n",
        "        self.fc2 = nn.Linear(2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate model, define loss and optimizer\n",
        "model = ANDNet()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "    y_pred = model(x_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(x_train)\n",
        "    predicted_classes = (predictions > 0.5).float()\n",
        "    print(\"\\nPredictions:\\n\", predictions)\n",
        "    print(\"Predicted Classes:\\n\", predicted_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/1000, Loss: 0.5643\n",
            "Epoch 200/1000, Loss: 0.5318\n",
            "Epoch 300/1000, Loss: 0.4658\n",
            "Epoch 400/1000, Loss: 0.4037\n",
            "Epoch 500/1000, Loss: 0.3718\n",
            "Epoch 600/1000, Loss: 0.3597\n",
            "Epoch 700/1000, Loss: 0.3548\n",
            "Epoch 800/1000, Loss: 0.3523\n",
            "Epoch 900/1000, Loss: 0.3510\n",
            "Epoch 1000/1000, Loss: 0.3499\n",
            "\n",
            "Predictions:\n",
            " tensor([[0.0074],\n",
            "        [0.0055],\n",
            "        [0.4919],\n",
            "        [0.4919]])\n",
            "Predicted Classes:\n",
            " tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n"
          ]
        }
      ],
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f688dc0b-f69e-422f-b4c6-b76af83dbea0",
        "outputId": "fa8aae62-3f62-4871-9ecc-ac837d5557ed"
      },
      "id": "f688dc0b-f69e-422f-b4c6-b76af83dbea0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q25.** Implement and train a neural network for the XOR gate (with hidden layer)."
      ],
      "metadata": {
        "id": "3bdaf997-3ba3-46a1-bc1b-a30a1f8249f5"
      },
      "id": "3bdaf997-3ba3-46a1-bc1b-a30a1f8249f5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q25 Code Task\n",
        "# Prepare the XOR gate dataset\n",
        "x_train = torch.tensor([[0,0], [0,1], [1,0], [1,1]], dtype=torch.float32)\n",
        "y_train = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "# Define a feedforward neural network with hidden layer\n",
        "class XORNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(XORNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 4)\n",
        "        self.fc2 = nn.Linear(4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate model, define loss and optimizer\n",
        "model = XORNet()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    y_pred = model(x_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch+1) % 500 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    predictions = model(x_train)\n",
        "    predicted_classes = (predictions > 0.5).float()\n",
        "    print(\"\\nPredictions:\\n\", predictions)\n",
        "    print(\"Predicted Classes:\\n\", predicted_classes)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500/5000, Loss: 0.3689\n",
            "Epoch 1000/5000, Loss: 0.0730\n",
            "Epoch 1500/5000, Loss: 0.0311\n",
            "Epoch 2000/5000, Loss: 0.0187\n",
            "Epoch 2500/5000, Loss: 0.0130\n",
            "Epoch 3000/5000, Loss: 0.0099\n",
            "Epoch 3500/5000, Loss: 0.0080\n",
            "Epoch 4000/5000, Loss: 0.0066\n",
            "Epoch 4500/5000, Loss: 0.0056\n",
            "Epoch 5000/5000, Loss: 0.0049\n",
            "\n",
            "Predictions:\n",
            " tensor([[0.0131],\n",
            "        [0.9976],\n",
            "        [0.9976],\n",
            "        [0.0017]])\n",
            "Predicted Classes:\n",
            " tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ],
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df04e51e-37cf-4bb9-a113-437e9efb30e9",
        "outputId": "b98d684b-1b04-4f68-f232-3be4120147be"
      },
      "id": "df04e51e-37cf-4bb9-a113-437e9efb30e9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}